FAIRification process,Tool,Description,Website,License,ResourceType,Type,Source,Confidence,Notes,,,,,,,,,,,,
,,,,if available,"what type this resource is. 
Select from this list [software, vocabulary, database, package]",“commercial” or “others”,"how this tool was discovered
“manual” or “bio.tools”",For auto-discovered tools.,,,,,,,,,,,,,
ETL,Bert,Bidirectional Encoder Representations from Transformers (BERT) is a Transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google. ,https://en.wikipedia.org/wiki/BERT_(language_model),,model,,,,,,,,,,,,,,,,
ETL,Collibra,Collibra Data Catalog empowers business users to quickly discover and understand data that matters so they can generate impactful insights that drive business value. Collibra Data Lineage: Collibra Data Lineage automatically maps relationships between data to show how data flows from system to system and how data sets are built, aggregated, end-to-end lineage visualization. Operationalizing data privacy, CCPA and GDPR compliance, Collibra delivers privacy from a Data Intelligent foundation that centralizes, automates and guides privacy workflows. Collibra Data Governance helps organizations understand their ever-growing amounts of data in a way that scales with growth and change,https://www.collibra.com/,Collibra,data catalog, schema validation, governance, entity versioning,NA,software,,,,schema validation, cataloging, and data governance entity versiong
ETL,Dublin Core,The Dublin Core Metadata Initiative or DCMI is an organization supporting innovation in metadata design and best practices across the metadata ecology. DCMI works openly and it supported by a paid-membership model. DCMI's activities include: work on architecture and modelling,https://dublincore.org/,,vocabulary,,,,,,,,,,,,,,,,
ETL,Hadoop,a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, each of which may be prone to failures.,https://hadoop.apache.org/,Hadoop,distributed computing,,software,,,,,,,,,,,,
ETL,Informatica,Informatica is the only Enterprise Cloud Data Management leader that accelerates data-driven digital transformation. Informatica enables companies to fuel innovation become more agile and realize new growth opportunities resulting in intelligent market disruptions,https://www.informatica.com/gb/about-us.html, cloud migration,,software,,,,,,,,,,,,,,,
ETL,OMOP,The OMOP Common Data Model allows for the systematic analysis of disparate observational databases. The concept behind this approach is to transform data contained within those databases into a common format (data model) as well as a common representation (terminologies vocabularies coding schemes) and then perform systematic analyses using a library of standard analytic routines that have been written based on the common format,https://www.ohdsi.org/data-standardization/the-common-data-model/, vocabularies, coding schemes), and then perform systematic analyses using a library of standard analytic routines that have been written based on the common format.,SNOMED INTERNATIONAL SNOMED CT LICENSE AGREEMENT,data model,,,,,,,,,,,,,
ETL,REDCap,REDCap is a secure web application for building and managing online surveys and databases. While REDCap can be used to collect virtually any type of data in any environment (including compliance with 21 CFR Part 11 FISMA HIPAA and GDPR),https://www.project-redcap.org/,,software,,,,,,,,,,,,,,,,
ETL,SDTM,SDTM provides a standard for organizing and formatting data to streamline processes in collection management analysis and reporting. Implementing SDTM supports data aggregation and warehousing; fosters mining and reuse; facilitates sharing; helps perform due diligence and other important data review activities; and improves the regulatory review and approval process. SDTM is also used in non-clinical data (SEND) medical devices and pharmacogenomics/genetics studies.,https://www.cdisc.org/standards/foundational/sdtm,,software,,,,,,,,,,,,,,,,
ETL,TAMR,Accelerating Analytic outcomes. The toughest analytics challenges need consolidated cleansed categorized data. Tamr’s data mastering solutions are designed to power timely actionable analytic insightsCloud-Native Master. Data Management (MDM). Tamr’s cloud-native data mastering solutions make it easy to connect internal and external data sources quickly to power analytic insights and drive business outcomes,https://www.tamr.com/,,software,,,,,,,,,,,,,,,,
ETL,TransMART,An Open-Source—Open-Data Community. Enabling collaboration for precision medicine through sharing integration standardization,https://i2b2transmart.org/, clinical data,,software,,,,,,,,,,,,,,,
ETL,TriFacta,Poor data quality can sink any analytics project. Trifacta helps you understand your data so you can quickly and accurately clean it up. Clean Blend & Standardize your Data. Data transformation. All the power with none of the code. Trifacta provides visual and intelligent guidance so you can get to insights faster.Automate Your Data Processes. Data pipelines. Manual repetitive data preparation processes don’t scale. Trifacta helps you build deploy and manage self-service data pipelines in minutes not months.,https://www.trifacta.com/,,software,,,,,,,,,,,,,,,,
ETL,Termite,TERMite (TERM identification, tagging & extraction) is the ultra-fast named entity recognition (NER) and extraction engine at the heart of our semantic analytics software suite.Coupled with our hand-curated VOCabs,https://www.scibite.com/platform/termite/,Termite,information extraction,,software,,,,,,,,,,,,,
ETL,fairifier,"A general-purpose FAIRifier on the basis of the OpenRefine data cleaning and wrangling tool and the RDF plugin. This FAIRifier enables a post-hoc FAIRification workflow: load an existing dataset, perform data wrangling tasks, add FAIR attributes to the data, generate a linked data version of the data and, finally, push the result to an online FAIR data infrastructure to make it accessible and discoverable. Literal values in a dataset can be replaced by identifiers either manually or by embedded, customizable script expressions. The interoperability of the dataset can be improved by connecting these identifiers into a meaningful semantic graph-structure of ontological classes and properties using the integrated RDF model editor. A provenance trail automatically keeps track of each modification and additionally enables “undo” operations and repetition of operations on similar datasets. A FAIR data export function opens up a metadata editor to provide information about the dataset itself.",,,,,,,,,,,,,,,,,,,
ETL,query tabular,galaxy only,,,,,,,,,,,,,,,,,,,
ETL,martview,Tool for data retrieval and data mining that integrates data from Ensembl. Through the web interface it allows you to apply a series of filters to create custom datasets which can be converted to several useful output formats.,,,,,,,,,,,,,,,,,,,
ETL,osirix,"OsiriX is an image processing software dedicated to DICOM images (“.dcm” / “.DCM” extension) produced by imaging equipment (MRI, CT, PET, PET-CT, SPECT-CT, Ultrasounds, …). It is fully compliant with the DICOM standard for image comunication and image file formats. OsiriX is able to receive images transferred by DICOM communication protocol from any PACS or imaging modality (C-STORE SCP/SCU, and Query/Retrieve : C-MOVE SCU/SCP, C-FIND SCU/SCP, C-GET SCU/SCP, WADO) .",,,,,,,,,,,,,,,,,,,
ETL,ms-data-core-api,"The ms-data-core-api is a free, open-source library for developing computational proteomics tools and pipelines. The Application Programming Interface, written in Java, enables rapid tool creation by providing a robust, pluggable programming interface and common data model. The data model is based on controlled vocabularies/ontologies and captures the whole range of data types included in common proteomics experimental workflows, going from spectra to peptide/protein identifications to quantitative results. The library contains readers for three of the most used Proteomics Standards Initiative standard file formats: mzML, mzIdentML, and mzTab. In addition to mzML, it also supports other common mass spectra data formats: dta, ms2, mgf, pkl, apl (text-based), mzXML and mzData (XML-based). Also, it can be used to read PRIDE XML, the original format used by the PRIDE database, one of the world-leading proteomics resources.",,,,,,,,,,,,,,,,,,,
ETL,snpator,deprecated,,,,,,,,,,,,,,,,,,,
ETL,disqover,"DISQOVER is a data integration platform for public, licensed and internal data. The Data Ingestion Engine enables transforming data into Linked Data which can be searched, navigated and analysed via the user interface and the API. The publicly accessible DISQOVER platform contains 140+ public data sources in life sciences and related domains.",,,,,,,,,,,,,,,,,,,
ETL,baget,"BAGET (Bacterial and Archaeal Gene Exploration Tool) is a web service designed to facilitate extraction of specific gene and protein sequences from completely determined prokaryotic genomes. Query results can be exported as a rich text format file for printing, archival or further analysis.
",,,,,,,,,,,,,,,,,,,
ETL,ncbi resources,,,,,,,,,,,,,,,,,,,,
ETL,repo,,,,,,,,,,,,,,,,,,,,
ETL,pga,,,,,,,,,,,,,,,,,,,,
