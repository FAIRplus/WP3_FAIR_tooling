,,last update:2021-02-08,,,,,,,
,,,,,,,,,
FAIRification process,Tool,Description,Website,License,Curation,,,,Notes
ETL,Bert,Bidirectional Encoder Representations from Transformers (BERT) is a Transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google. ,https://en.wikipedia.org/wiki/BERT_(language_model),,manual,,,,
ETL,Collibra,Collibra Data Catalog empowers business users to quickly discover and understand data that matters so they can generate impactful insights that drive business value. Collibra Data Lineage: Collibra Data Lineage automatically maps relationships between data to show how data flows from system to system and how data sets are built, aggregated,,manual,,,,
ETL,Dublin Core,The Dublin Core Metadata Initiative or DCMI is an organization supporting innovation in metadata design and best practices across the metadata ecology. DCMI works openly and it supported by a paid-membership model. DCMI's activities include: work on architecture and modelling,https://dublincore.org/,,manual,,,,
ETL,Hadoop,a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability,,manual,,,,
"ETL, relational data",Informatica,Informatica is the only Enterprise Cloud Data Management leader that accelerates data-driven digital transformation. Informatica enables companies to fuel innovation become more agile and realize new growth opportunities resulting in intelligent market disruptions,https://www.informatica.com/gb/about-us.html,,manual,,,,
ETL,OMOP,The OMOP Common Data Model allows for the systematic analysis of disparate observational databases. The concept behind this approach is to transform data contained within those databases into a common format (data model) as well as a common representation (terminologies vocabularies coding schemes) and then perform systematic analyses using a library of standard analytic routines that have been written based on the common format,https://www.ohdsi.org/data-standardization/the-common-data-model/,,manual,,,,
ETL,REDCap,REDCap is a secure web application for building and managing online surveys and databases. While REDCap can be used to collect virtually any type of data in any environment (including compliance with 21 CFR Part 11 FISMA HIPAA and GDPR),https://www.project-redcap.org/,,manual,,,,
ETL,SDTM,SDTM provides a standard for organizing and formatting data to streamline processes in collection management analysis and reporting. Implementing SDTM supports data aggregation and warehousing; fosters mining and reuse; facilitates sharing; helps perform due diligence and other important data review activities; and improves the regulatory review and approval process. SDTM is also used in non-clinical data (SEND) medical devices and pharmacogenomics/genetics studies.,https://www.cdisc.org/standards/foundational/sdtm,,manual,,,,
ETL,TAMR,Accelerating Analytic outcomes. The toughest analytics challenges need consolidated cleansed categorized data. Tamr’s data mastering solutions are designed to power timely actionable analytic insightsCloud-Native Master. Data Management (MDM). Tamr’s cloud-native data mastering solutions make it easy to connect internal and external data sources quickly to power analytic insights and drive business outcomes,https://www.tamr.com/,,manual,,,,
ETL,TransMART,An Open-Source—Open-Data Community. Enabling collaboration for precision medicine through sharing integration standardization,https://i2b2transmart.org/,,manual,,,,
ETL,TriFacta,Poor data quality can sink any analytics project. Trifacta helps you understand your data so you can quickly and accurately clean it up. Clean Blend & Standardize your Data. Data transformation. All the power with none of the code. Trifacta provides visual and intelligent guidance so you can get to insights faster.Automate Your Data Processes. Data pipelines. Manual repetitive data preparation processes don’t scale. Trifacta helps you build deploy and manage self-service data pipelines in minutes not months.,https://www.trifacta.com/,,manual,,,,
ETL,Termite,TERMite (TERM identification,,,manual,,,,
"ETL, extraction, mapping, documentation, data structure, field mapping, ",Rabbit in a hat,"scan databases in SQL Server, Oracle, PostgreSQL, MySQL, MS Access, Amazon RedShift, Google BigQuery, SAS files and CSV files, report contains information on tables, fields, and frequency distributions of values. Cutoff on the minimum frequency of values to protect patient privacy. WhiteRabbit can be run with a graphical user interface or from the command prompt. Interactive tool (Rabbit in a Hat) for designing the ETL using the scan report as basis. Rabbit in a Hat generates ETL specification document according to OMOP template",http://ohdsi.github.io/WhiteRabbit/RabbitInAHat.html,Apache License 2.0,manual,,,,
"terminology, transform",Usage,a software tool created by the Observational Health Data Sciences and Informatics (OHDSI) team and is used to help in the process of mapping codes from a source system into the standard terminologies stored in the Observational Medical Outcomes Partnership (OMOP) Vocabulary,https://www.ohdsi.org/web/wiki/doku.php?id=documentation:software:usagi,Apache License 2.0.,manual,,,,
"Identifier generation, ETL",Athena,"Automated Terminology Harmonization, Extraction and Normalization for Analytics",https://athena.ohdsi.org/search-terms/terms,SNOMED INTERNATIONAL SNOMED CT LICENSE AGREEMENT,manual,,,,
"ETL, datawarehouse",Postgresql,a free and open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance.,https://www.postgresql.org/,The PostgreSQL Licence (PostgreSQL),manual,,,,
"ETL, data validation, data characterization",ACHILLES,Automated Characterization of Health Information at Large-scale Longitudinal Evidence Systems (ACHILLES) – descriptive statistics about an OMOP CDM v4 database.,https://www.ohdsi.org/analytic-tools/achilles-for-data-characterization/,Apache License 2.0,manual,,,,
"ETL, data validation",DataQualityDashboard,"run a series of data quality checks against an OMOP CDM instance (currently supports v5.3.1 and v5.2.2). It systematically runs the checks, evaluates the checks against some pre-specified threshold, and then communicates what was done in a transparent and easily understandable way",https://ohdsi.github.io/DataQualityDashboard/,Apache License 2.0,manual,,,,
"ETL, data analysis",ATLAS,"a free, publicly available web-based, open-source software application developed by the OHDSI community to support the design and execution of observational analyses to generate real world evidence from patient level observational data.",https://github.com/OHDSI/Atlas/wiki,Apache License 2.0,manual,,,,
"ETL, semantics, rdf database",Stardog ,"Triple Store Database, Provide an enterprise knowledge graph as FAIR+ data catalogue",https://www.stardog.com/,,manual,,,,
ETL. Data integration,Talend,"Talend provides a unified approach that combines rapid data integration, transformation, and mapping with automated quality checks to ensure trustworthy data every step of the way.",https://www.talend.com/products/integrate-data/,,,,,,
